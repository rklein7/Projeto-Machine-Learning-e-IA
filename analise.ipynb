{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "53d3dce2",
      "metadata": {
        "id": "53d3dce2"
      },
      "source": [
        "# Projeto do Nanodegree - 2025/1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "55bc3e39",
      "metadata": {
        "id": "55bc3e39"
      },
      "source": [
        "## Introdução\n",
        "\n",
        "Este notebook faz parte do projeto do Nanodegree 2025/1 da disciplina de Machine Learning & Inteligência Artificial.\n",
        "Seu objetivo é analisar, explorar, preparar os dados e aplicar a modelos para a tarefa de previsão de evasão de estudantes em um curso online síncrono promovido pela PensComp."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fD6qL_ah1o8h",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fD6qL_ah1o8h",
        "outputId": "15f4d0c1-1ba6-48af-d1f3-e64050063c19"
      },
      "outputs": [],
      "source": [
        "pip install unidecode shap"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1116de78",
      "metadata": {},
      "source": [
        "## 1. Configuração do Ambiente"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b3e36e6e",
      "metadata": {},
      "source": [
        "### 1.1. Importação de Bibliotecas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "44290807",
      "metadata": {
        "id": "44290807"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import unidecode\n",
        "import shap\n",
        "\n",
        "# Modelagem e Métricas\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Configurações de visualização\n",
        "sns.set_style('whitegrid')\n",
        "plt.rcParams['figure.figsize'] = (10, 6)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2d3e4f4e",
      "metadata": {},
      "source": [
        "### 1.2. Definição de Constantes\n",
        "\n",
        "Centralizar constantes melhora a legibilidade e facilita a manutenção do código. Se precisarmos ajustar um parâmetro (como o número de dias para considerar evasão), podemos fazer isso em um único lugar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1b2c3d4",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Constantes do Projeto\n",
        "DIAS_INATIVIDADE_EVASAO = 60\n",
        "LIMITE_NAN_DROP = 0.70 # Limite de 70% de valores nulos para remover uma coluna\n",
        "RANDOM_STATE = 42 # Semente para garantir a reprodutibilidade dos resultados"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d5e6f7g8",
      "metadata": {},
      "source": [
        "### 1.3. Funções Auxiliares\n",
        "\n",
        "Criar funções para tarefas repetitivas (como avaliar modelos) torna o notebook mais limpo e segue o princípio DRY (Don't Repeat Yourself)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "h9i0j1k2",
      "metadata": {},
      "outputs": [],
      "source": [
        "def avaliar_modelo(nome_modelo, y_verdadeiro, y_previsao, ax=None):\n",
        "    \"\"\"\n",
        "    Imprime o relatório de classificação e plota a matriz de confusão para um modelo.\n",
        "    \"\"\"\n",
        "    print(f\"\\n--- Relatório de Classificação: {nome_modelo} ---\")\n",
        "    print(classification_report(y_verdadeiro, y_previsao))\n",
        "\n",
        "    # Plotar matriz de confusão\n",
        "    cm = confusion_matrix(y_verdadeiro, y_previsao)\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "    \n",
        "    if ax:\n",
        "        disp.plot(cmap=plt.cm.Blues, ax=ax, colorbar=False)\n",
        "        ax.set_title(f'Matriz de Confusão - {nome_modelo}')\n",
        "    else:\n",
        "        disp.plot(cmap=plt.cm.Blues)\n",
        "        plt.title(f'Matriz de Confusão - {nome_modelo}')\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "87f244a7",
      "metadata": {
        "id": "87f244a7"
      },
      "source": [
        "## 2. Carga e Análise Exploratória dos Dados (EDA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c65a767",
      "metadata": {
        "id": "2c65a767"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('dados_projeto_evasao_treino - Copia.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34ac8ac0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "34ac8ac0",
        "outputId": "bea241f0-9c21-4f4d-9244-6065b9a99014"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e6fb2779",
      "metadata": {
        "id": "e6fb2779"
      },
      "source": [
        "### 2.1. Limpeza e Preparação dos Dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74e053cc",
      "metadata": {
        "id": "74e053cc"
      },
      "outputs": [],
      "source": [
        "# Remover colunas de ID e alunos que nunca acessaram\n",
        "df = df.drop(\"Unnamed: 0\", axis=1)\n",
        "df = df[df['ts_primeiro_acesso'] != 0]\n",
        "\n",
        "# Converter timestamps para datetime\n",
        "df['ts_primeiro_acesso'] = pd.to_datetime(df['ts_primeiro_acesso'], unit='s')\n",
        "df['ts_ultimo_acesso'] = pd.to_datetime(df['ts_ultimo_acesso'], unit='s')\n",
        "\n",
        "# Limpeza da coluna de cidade\n",
        "df['ds_cidade_usuario'] = (\n",
        "    df['ds_cidade_usuario']\n",
        "    .astype(str)\n",
        "    .str.strip()\n",
        "    .str.upper()\n",
        "    .apply(unidecode.unidecode)\n",
        ")\n",
        "df['ds_cidade_usuario'].replace(\"NAN\", \"CIDADE NAO INFORMADA\", inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "n_Em1vkG082V",
      "metadata": {
        "id": "n_Em1vkG082V"
      },
      "source": [
        "### 2.2. Tratamento de Valores Ausentes\n",
        "A estratégia de tratamento de valores nulos é crucial. Removemos colunas com excesso de dados faltantes (>70%) e preenchemos as demais com base em hipóteses de negócio (ex: nulo em engajamento significa atividade zero) ou estatísticas robustas (mediana)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "l8SL5q-Y06k1",
      "metadata": {
        "id": "l8SL5q-Y06k1"
      },
      "outputs": [],
      "source": [
        "# Identificar colunas a serem removidas com base no limiar\n",
        "missing_ratio = df.isnull().mean()\n",
        "colunas_para_remover = missing_ratio[missing_ratio > LIMITE_NAN_DROP].index\n",
        "df.drop(columns=colunas_para_remover, inplace=True)\n",
        "print(f\"Colunas removidas por excesso de NAs: {list(colunas_para_remover)}\")\n",
        "\n",
        "# Preenchimento com zero (ausência de atividade)\n",
        "cols_fill_zero = [\"vl_desempenho_questionario\", \"vl_engajamento_usuario_por_intervalo\", \n",
        "                  \"vl_engajamento_usuario_intradia\", \"vl_desempenho_usuario\", \"vl_media_notas\"]\n",
        "for col in cols_fill_zero:\n",
        "    if col in df.columns:\n",
        "        df[col] = df[col].fillna(0)\n",
        "\n",
        "# Preenchimento com mediana (variáveis de tempo contínuas)\n",
        "cols_fill_median = [\"vl_medio_tempo_questionario\", \"vl_medio_tempo_questionario_avaliado\"]\n",
        "for col in cols_fill_median:\n",
        "    if col in df.columns:\n",
        "      median_val = df[col].median()\n",
        "      df[col] = df[col].fillna(median_val)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "l4m5n6o7",
      "metadata": {},
      "source": [
        "### 2.3. Análise Visual dos Dados"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "s2KmJhg67DnO",
      "metadata": {
        "id": "s2KmJhg67DnO"
      },
      "source": [
        "#### Distribuição do Desempenho Geral e Dias de Inatividade\n",
        "\n",
        "Analisar a distribuição destas duas variáveis é fundamental, pois elas formam a base da nossa definição de evasão. Notamos uma alta concentração de alunos com desempenho zero e um grande número de alunos inativos há muito tempo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "p8q9r0s1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "outputId": "t2u3v4w5"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "# Gráfico de Desempenho\n",
        "sns.histplot(df['vl_desempenho_usuario'], bins=20, kde=True, ax=axes[0], color='skyblue')\n",
        "axes[0].set_title('Distribuição do Desempenho dos Alunos')\n",
        "axes[0].set_xlabel('Desempenho')\n",
        "axes[0].set_ylabel('Frequência')\n",
        "\n",
        "# Gráfico de Dias desde o Último Acesso\n",
        "sns.histplot(df['nr_dias_desde_ultimo_acesso'], bins=30, kde=True, ax=axes[1], color='salmon')\n",
        "axes[1].set_title('Distribuição dos Dias Desde o Último Acesso')\n",
        "axes[1].set_xlabel('Dias Desde o Último Acesso')\n",
        "axes[1].set_ylabel('Frequência')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "v6w7x8y9",
      "metadata": {},
      "source": [
        "#### Heatmap de Correlação\n",
        "\n",
        "O heatmap nos ajuda a identificar relações lineares entre as variáveis. Correlações fortes podem indicar redundância de features, enquanto a correlação com a variável-alvo (que criaremos a seguir) é um forte indicador de poder preditivo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "z0a1b2c3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 800
        },
        "outputId": "d4e5f6g7"
      },
      "outputs": [],
      "source": [
        "df_numeric = df.select_dtypes(include=np.number)\n",
        "\n",
        "plt.figure(figsize=(14, 10))\n",
        "sns.heatmap(df_numeric.corr(), annot=True, cmap='coolwarm', fmt='.2f', annot_kws={'size': 8})\n",
        "plt.title('Heatmap de Correlação entre Variáveis Numéricas')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d6s8lo3NHaDr",
      "metadata": {
        "id": "d6s8lo3NHaDr"
      },
      "source": [
        "## 3. Engenharia de Features\n",
        "\n",
        "Nesta etapa, criamos novas variáveis a partir dos dados existentes para capturar informações de negócio relevantes e acionáveis."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "h8i9j0k1",
      "metadata": {},
      "source": [
        "### 3.1. Criação da Variável Alvo (`evadiu`)\n",
        "\n",
        "Definimos uma regra de negócio para classificar um aluno como evadido. Essa será a variável que nossos modelos tentarão prever.\n",
        "\n",
        "> **Regra:** Se o aluno tem **desempenho zero** E está **inativo há mais de 60 dias**, ele é classificado como `evadiu = 1`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wREtrahDHGjs",
      "metadata": {
        "id": "wREtrahDHGjs"
      },
      "outputs": [],
      "source": [
        "df['evadiu'] = ((df['vl_desempenho_usuario'] == 0) & (df['nr_dias_desde_ultimo_acesso'] > DIAS_INATIVIDADE_EVASAO)).astype(int)\n",
        "print(\"Distribuição da variável 'evadiu':\")\n",
        "print(df['evadiu'].value_counts(normalize=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5m1prvYuHz1l",
      "metadata": {
        "id": "5m1prvYuHz1l"
      },
      "source": [
        "### 3.2. Criação de Perfis de Risco\n",
        "\n",
        "Para uma análise mais estratégica, segmentamos os alunos em perfis de risco. Isso permite que a PensComp direcione ações específicas para cada grupo, em vez de uma abordagem genérica."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "j2CGwbrYH1d6",
      "metadata": {
        "id": "j2CGwbrYH1d6"
      },
      "outputs": [],
      "source": [
        "def criar_perfil(row):\n",
        "    if row[\"vl_desempenho_usuario\"] == 0 and row[\"nr_dias_desde_ultimo_acesso\"] > DIAS_INATIVIDADE_EVASAO:\n",
        "        return \"Alto Risco (Evasão)\"\n",
        "    elif row[\"vl_desempenho_usuario\"] > 0.7 and row[\"nr_dias_desde_ultimo_acesso\"] > DIAS_INATIVIDADE_EVASAO:\n",
        "        return \"Reengajamento Urgente\"\n",
        "    elif row[\"vl_desempenho_usuario\"] < 0.3 and row['nr_dias_desde_ultimo_acesso'] <= DIAS_INATIVIDADE_EVASAO:\n",
        "        return \"Apoio Pedagógico\"\n",
        "    else:\n",
        "        return \"Estável\"\n",
        "\n",
        "df[\"perfil\"] = df.apply(criar_perfil, axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "l2m3n4o5",
      "metadata": {},
      "source": [
        "#### Visualização da Distribuição dos Perfis\n",
        "\n",
        "Visualizar a contagem de alunos em cada perfil nos dá uma noção clara da urgência e do tamanho de cada segmento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "p6q7r8s9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "outputId": "t0u1v2w3"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "sns.countplot(y='perfil', data=df, order=df['perfil'].value_counts().index, palette='viridis')\n",
        "plt.title('Contagem de Alunos por Perfil de Risco')\n",
        "plt.xlabel('Quantidade de Alunos')\n",
        "plt.ylabel('Perfil')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "oGg3NTk8SJSF",
      "metadata": {
        "id": "oGg3NTk8SJSF"
      },
      "source": [
        "## 4. Pré-Processamento e Modelagem"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "x4y5z6a7",
      "metadata": {},
      "source": [
        "### 4.1. Preparação dos Dados para os Modelos\n",
        "\n",
        "Aqui, preparamos os conjuntos de dados `X` (features) e `y` (alvo) e os padronizamos para que os modelos de Machine Learning possam processá-los corretamente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b8c9d0e1",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Seleção do Alvo (y) e Features (X)\n",
        "y = df[\"evadiu\"]\n",
        "X = df.drop(columns=[\"evadiu\", \"perfil\", \"ds_cidade_usuario\"], errors=\"ignore\")\n",
        "\n",
        "# Remover colunas de data/hora, pois os modelos não as processam diretamente\n",
        "X = X.select_dtypes(exclude=[\"datetime64[ns]\"])\n",
        "\n",
        "# Padronização das Features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
        "\n",
        "# Divisão em Treino e Teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_scaled, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y\n",
        ")\n",
        "\n",
        "print(f\"Tamanho do conjunto de treino: {X_train.shape}\")\n",
        "print(f\"Tamanho do conjunto de teste: {X_test.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "epHYXvGU81D7",
      "metadata": {
        "id": "epHYXvGU81D7"
      },
      "source": [
        "### 4.2. Treinamento e Avaliação dos Modelos"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2g3h4i5",
      "metadata": {},
      "source": [
        "#### Modelo 1: Regressão Logística\n",
        "\n",
        "Começamos com a Regressão Logística por ser um modelo simples, rápido e altamente interpretável, servindo como um excelente baseline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "OnlS1XjtAxiA",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OnlS1XjtAxiA",
        "outputId": "5356dff5-ae2d-4f7a-ea73-59f2d1809563"
      },
      "outputs": [],
      "source": [
        "log_model = LogisticRegression(random_state=RANDOM_STATE, max_iter=1000)\n",
        "log_model.fit(X_train, y_train)\n",
        "y_pred_log = log_model.predict(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "j6k7l8m9",
      "metadata": {},
      "source": [
        "#### Modelo 2: Random Forest\n",
        "\n",
        "Em seguida, usamos o Random Forest, um modelo de ensemble robusto que captura relações não-lineares e geralmente oferece maior performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2OBRPPgEA6S3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2OBRPPgEA6S3",
        "outputId": "e6e24259-ee0a-4144-b364-2060073858b6"
      },
      "outputs": [],
      "source": [
        "rf_model = RandomForestClassifier(random_state=RANDOM_STATE)\n",
        "rf_model.fit(X_train, y_train)\n",
        "y_pred_rf = rf_model.predict(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "n0o1p2q3",
      "metadata": {},
      "source": [
        "#### Modelo 3: Rede Neural\n",
        "\n",
        "Por fim, implementamos uma Rede Neural simples, capaz de aprender padrões complexos, para buscar a máxima performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "jxTrSTd6MNe2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jxTrSTd6MNe2",
        "outputId": "a69ea9da-21f0-4d4a-ff1d-6082dbb168d5"
      },
      "outputs": [],
      "source": [
        "# Arquitetura do modelo\n",
        "nn_model = Sequential([\n",
        "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    Dropout(0.3),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "nn_model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "history = nn_model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_split=0.2,\n",
        "    epochs=100,\n",
        "    batch_size=16,\n",
        "    callbacks=[early_stop],\n",
        "    verbose=0 # Silenciar output do treino\n",
        ")\n",
        "\n",
        "y_pred_nn_prob = nn_model.predict(X_test)\n",
        "y_pred_nn = (y_pred_nn_prob > 0.5).astype(\"int32\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "r4s5t6u7",
      "metadata": {},
      "source": [
        "### 4.3. Comparação dos Resultados e Matrizes de Confusão\n",
        "\n",
        "Com a função `avaliar_modelo`, podemos comparar de forma limpa e direta a performance dos três modelos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "v8w9x0y1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 800
        },
        "outputId": "z2a3b4c5"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "\n",
        "avaliar_modelo(\"Regressão Logística\", y_test, y_pred_log, ax=axes[0])\n",
        "avaliar_modelo(\"Random Forest\", y_test, y_pred_rf, ax=axes[1])\n",
        "avaliar_modelo(\"Rede Neural\", y_test, y_pred_nn, ax=axes[2])\n",
        "\n",
        "axes[1].set_ylabel(\"\")\n",
        "axes[2].set_ylabel(\"\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d6e7f8g9",
      "metadata": {},
      "source": [
        "### 4.4. Nota Importante sobre a Performance Perfeita\n",
        "\n",
        "Observamos que todos os modelos, especialmente a Rede Neural, alcançaram 100% de precisão, recall e acurácia no conjunto de teste. Embora pareça um resultado ideal, é fundamental entender a causa.\n",
        "\n",
        "**Isso não é um erro, mas uma consequência do desenho do problema.**\n",
        "\n",
        "A variável-alvo `evadiu` foi criada com uma regra determinística baseada em `vl_desempenho_usuario` e `nr_dias_desde_ultimo_acesso`. Como essas mesmas variáveis (ou outras fortemente correlacionadas) estão presentes nas features de treino, os modelos aprenderam a replicar perfeitamente essa regra.\n",
        "\n",
        "**Conclusão Prática:** O modelo é extremamente eficaz para **classificar o perfil atual de um aluno** e identificar quem já se encaixa nos critérios de evasão. No entanto, ele não está *prevendo* uma evasão futura, mas sim *identificando* um estado atual."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "h0i1j2k3",
      "metadata": {},
      "source": [
        "### 4.5. Validação Cruzada\n",
        "\n",
        "Para confirmar a estabilidade dos modelos, aplicamos a Validação Cruzada. Isso nos mostra se a alta performance se mantém em diferentes subconjuntos dos dados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "V2n_yfzpDhmc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V2n_yfzpDhmc",
        "outputId": "ca7a3cfa-c93d-40e0-faf5-78c6e420d453"
      },
      "outputs": [],
      "source": [
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
        "\n",
        "scores_log = cross_val_score(log_model, X_scaled, y, cv=cv, scoring=\"f1_weighted\")\n",
        "scores_rf = cross_val_score(rf_model, X_scaled, y, cv=cv, scoring=\"f1_weighted\")\n",
        "\n",
        "print(\"\\nF1-score Ponderado (Validação Cruzada)\")\n",
        "print(f\"Regressão Logística: {scores_log.mean():.4f} ± {scores_log.std():.4f}\")\n",
        "print(f\"Random Forest: {scores_rf.mean():.4f} ± {scores_rf.std():.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "l4m5n6o7p",
      "metadata": {},
      "source": [
        "## 5. Interpretabilidade do Modelo com SHAP (XAI)\n",
        "\n",
        "Usamos o SHAP para entender *quais* features são mais importantes para as decisões do modelo mais robusto (Random Forest). Isso adiciona transparência e confiança aos resultados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "76eefc28",
      "metadata": {},
      "outputs": [],
      "source": [
        "explainer_rf = shap.TreeExplainer(rf_model)\n",
        "shap_values_rf = explainer_rf.shap_values(X_test)\n",
        "\n",
        "shap.summary_plot(shap_values_rf[1], X_test, feature_names=X_test.columns, plot_type='bar', title='Importância Global das Features (Random Forest)')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "q8r9s0t1",
      "metadata": {},
      "source": [
        "O gráfico SHAP confirma nossa análise: `vl_desempenho_usuario` e `nr_dias_desde_ultimo_acesso` são as variáveis mais impactantes, pois são as que definem a própria evasão. Isso valida que o modelo aprendeu corretamente a lógica de negócio."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "u2v3w4x5",
      "metadata": {},
      "source": [
        "## 6. Conclusões e Próximos Passos"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "y6z7a8b9",
      "metadata": {},
      "source": [
        "### Conclusões do Projeto\n",
        "\n",
        "1.  **Modelos Eficazes:** Conseguimos construir modelos de Machine Learning que classificam com 100% de acerto os alunos que se encaixam na definição de evasão estabelecida pelo negócio (desempenho zero e inatividade superior a 60 dias).\n",
        "2.  **Validação da Lógica de Negócio:** A análise de interpretabilidade (SHAP) confirmou que as variáveis de desempenho e inatividade são, de fato, os fatores decisivos, validando a regra de negócio criada.\n",
        "3.  **Segmentação Acionável:** A criação de \"Perfis de Risco\" permite que a PensComp vá além da simples classificação e adote estratégias focadas para cada segmento de alunos, como campanhas de reengajamento ou oferta de apoio pedagógico.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0d1e2f3",
      "metadata": {},
      "source": [
        "### Próximos Passos: Evoluindo para um Modelo Preditivo\n",
        "\n",
        "O maior valor para o negócio está em **prever a evasão antes que ela aconteça**. Para evoluir este projeto de um classificador de estado atual para um modelo preditivo proativo, os próximos passos seriam:\n",
        "\n",
        "1.  **Reformular o Problema (Engenharia de Features Temporal):**\n",
        "    * **Definir uma Janela de Observação:** Usar apenas os dados das primeiras **2 ou 3 semanas** de atividade de cada aluno.\n",
        "    * **Definir uma Janela de Predição:** Criar a variável-alvo `evadira_nos_proximos_60_dias`, que seria `1` se o aluno, *após* a janela de observação, ficasse inativo.\n",
        "\n",
        "2.  **Ajuste Fino de Hiperparâmetros:**\n",
        "    * Utilizar técnicas como `GridSearchCV` ou `RandomizedSearchCV` para encontrar a melhor combinação de hiperparâmetros para os modelos (ex: `max_depth`, `n_estimators` no Random Forest), otimizando a performance preditiva.\n",
        "\n",
        "3.  **Implantação (Deploy):**\n",
        "    * Empacotar o modelo treinado em uma API (usando Flask ou FastAPI) para que possa ser consumido por outros sistemas, permitindo, por exemplo, a criação de um painel de controle em tempo real que alerte sobre alunos em risco."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
